{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ba883a-9ee5-4708-9d3d-866d4e65b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b969d712-3632-4cbb-9082-e419a1042aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1506 images belonging to 3 classes.\n",
      "Found 215 images belonging to 3 classes.\n",
      "Found 431 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = r'path to train dataset'\n",
    "val_dir = r'path to validation dataset'\n",
    "test_dir = r'path to test dataset'\n",
    "\n",
    "# Image Data Generators\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62c609cd-2899-4be7-a865-0ad81842858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a56c25e4-61f1-46e5-8f7e-8c546f93870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(3, activation='softmax')(x)  # Assuming 3 classes\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "478e2319-d8fe-4273-b065-caec1e2c452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6558076a-588d-4bb9-bf40-e69a9ca18652",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13419d65-6d8e-42f0-bb82-ec613e50251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4f7de0b-ab63-459d-8a39-31ac380b5e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 540s 11s/step - loss: 0.6493 - accuracy: 0.7815 - val_loss: 0.2815 - val_accuracy: 0.9115\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 491s 10s/step - loss: 0.2230 - accuracy: 0.9193 - val_loss: 0.3033 - val_accuracy: 0.8802\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 505s 11s/step - loss: 0.1818 - accuracy: 0.9322 - val_loss: 0.2434 - val_accuracy: 0.9323\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 509s 11s/step - loss: 0.1287 - accuracy: 0.9573 - val_loss: 0.1809 - val_accuracy: 0.9531\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 541s 12s/step - loss: 0.0908 - accuracy: 0.9681 - val_loss: 0.1666 - val_accuracy: 0.9531\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 507s 11s/step - loss: 0.0635 - accuracy: 0.9801 - val_loss: 0.1519 - val_accuracy: 0.9479\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 478s 10s/step - loss: 0.0469 - accuracy: 0.9905 - val_loss: 0.1563 - val_accuracy: 0.9583\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 477s 10s/step - loss: 0.0391 - accuracy: 0.9932 - val_loss: 0.1781 - val_accuracy: 0.9323\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 383s 8s/step - loss: 0.0345 - accuracy: 0.9953 - val_loss: 0.0990 - val_accuracy: 0.9740\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 303s 6s/step - loss: 0.0249 - accuracy: 0.9973 - val_loss: 0.1117 - val_accuracy: 0.9531\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 334s 7s/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 0.1253 - val_accuracy: 0.9479\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 365s 8s/step - loss: 0.0184 - accuracy: 0.9980 - val_loss: 0.1169 - val_accuracy: 0.9583\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 376s 8s/step - loss: 0.0174 - accuracy: 0.9980 - val_loss: 0.1192 - val_accuracy: 0.9531\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9986Restoring model weights from the end of the best epoch: 9.\n",
      "47/47 [==============================] - 353s 8s/step - loss: 0.0163 - accuracy: 0.9986 - val_loss: 0.1515 - val_accuracy: 0.9479\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    epochs=100,  # Set a high number for epochs; early stopping will handle stopping early.\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48b88e22-df56-4263-a582-203f7fcec426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 86s 6s/step - loss: 0.1418 - accuracy: 0.9519\n",
      "Test accuracy: 0.9519230723381042\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7964f25-47f5-4573-a36b-8a84a42db6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARUN PN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('vgg16_image_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eff4b94b-f41d-4618-a9d4-b29c7b7ab47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 367ms/step\n",
      "Predicted Label: Potato___healthy\n",
      "Predictions: [[2.6475516e-04 1.3603952e-02 9.8613131e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('vgg16_image_classification_model.h5')\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Load the image\n",
    "    img_array = image.img_to_array(img)  # Convert to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize the image\n",
    "    return img_array\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_image(img_path):\n",
    "    img_array = preprocess_image(img_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    class_indices = {v: k for k, v in train_generator.class_indices.items()}  # Get class labels\n",
    "    import json\n",
    "    with open(\"class_names.json\",\"w\") as f:\n",
    "        json.dump(class_indices,f,indent=4)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    predicted_label = class_indices[predicted_class[0]]\n",
    "    return predicted_label, predictions\n",
    "\n",
    "# Test the model with an image path\n",
    "img_path = r\"Data\" # Path to test image\n",
    "predicted_label, predictions = predict_image(img_path)\n",
    "print(f'Predicted Label: {predicted_label}')\n",
    "print(f'Predictions: {predictions}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be0344-8208-49ec-8be3-0367d163d14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
